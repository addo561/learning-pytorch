{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOTkRC9IhtotuDlnK18dNfr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/addo561/learning-pytorch/blob/main/Paper-implementations/Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "!pip install labml-nn"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySFzdh8Xelp-",
        "outputId": "38020241-05d1-40a3-e38b-6517507f0d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: labml-nn in /usr/local/lib/python3.11/dist-packages (0.4.137)\n",
            "Collecting labml==0.4.168 (from labml-nn)\n",
            "  Using cached labml-0.4.168-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: labml-helpers==0.4.89 in /usr/local/lib/python3.11/dist-packages (from labml-nn) (0.4.89)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from labml-nn) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.11/dist-packages (from labml-nn) (0.18.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from labml-nn) (0.21.0+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from labml-nn) (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from labml-nn) (2.0.2)\n",
            "Requirement already satisfied: fairscale in /usr/local/lib/python3.11/dist-packages (from labml-nn) (0.4.13)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from labml==0.4.168->labml-nn) (3.1.44)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from labml==0.4.168->labml-nn) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->labml-nn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->labml-nn) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext->labml-nn) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext->labml-nn) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->labml-nn) (11.2.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->labml==0.4.168->labml-nn) (4.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->labml-nn) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext->labml-nn) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext->labml-nn) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext->labml-nn) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext->labml-nn) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->labml==0.4.168->labml-nn) (5.0.2)\n",
            "Using cached labml-0.4.168-py3-none-any.whl (130 kB)\n",
            "Installing collected packages: labml\n",
            "  Attempting uninstall: labml\n",
            "    Found existing installation: labml 0.5.3\n",
            "    Uninstalling labml-0.5.3:\n",
            "      Successfully uninstalled labml-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "labml-app 0.5.14 requires labml>=0.5.2, but you have labml 0.4.168 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed labml-0.4.168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn  as nn\n",
        "from labml_helpers.module import Module"
      ],
      "metadata": {
        "id": "SGvWG1Gqh08c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear projections for shortcut connection"
      ],
      "metadata": {
        "id": "kHx1O5mhxgTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for f(x) + Ws(Linear projection) * x if  feature map and x is not of same shape\n",
        "class shortcut_projection(Module):\n",
        "  def __init__(self, in_channels: int,out_channels: int,stride: int):\n",
        "    super().__init__()\n",
        "    self.conv  = nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=stride)\n",
        "    self.bn  =  nn.BatchNorm2d(out_channels)\n",
        "\n",
        "  def forward(self,x: torch.Tensor):\n",
        "    return  self.bn(self.conv(x))\n"
      ],
      "metadata": {
        "id": "IApWnh4Zt4mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Residual Block"
      ],
      "metadata": {
        "id": "d69xJrNxxlcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(Module):\n",
        "  def __init__(self,in_channels: int,out_channels: int,stride: int):\n",
        "    super().__init__()\n",
        "    #1st conv  block\n",
        "    self.conv1 = nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride,padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.act1 = nn.ReLU()\n",
        "\n",
        "    #2nd conv block with stride  1\n",
        "    self.conv2 = nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=1,padding=1)\n",
        "    self.bn2 =  nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    #Shortcut connection should be a projection if the stride length is not 1 or if the number of channels change\n",
        "    if stride!= 1 or in_channels != out_channels:\n",
        "      self.shortcut =  shortcut_projection(in_channels,out_channels,stride)\n",
        "    else:\n",
        "      self.shortcut = nn.Identity()\n",
        "\n",
        "    self.act2 = nn.ReLU()\n",
        "\n",
        "  def  forward(self,x: torch.Tensor):\n",
        "    shortcut  = self.shortcut(x)\n",
        "    x = self.act1(self.bn1(self.conv1(x)))\n",
        "    x = self.bn2(self.conv2)\n",
        "\n",
        "    return self.act2(x +  shortcut)\n",
        "\n"
      ],
      "metadata": {
        "id": "5g9dPGOkxcTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleneckResidualBlock(Module):\n",
        "  def __init__(self, in_channels:  int,bottleneck_channels: int,out_channels: int,stride: int):\n",
        "    super().__init__()\n",
        "    #first conv block\n",
        "    self.conv1 = nn.Conv2d(in_channels,bottleneck_channels,kernel_size=1,stride=1)\n",
        "    self.bn1 =  nn.BatchNorm2d(bottleneck_channels)\n",
        "    self.act1 = nn.ReLU()\n",
        "\n",
        "    #2nd conv block\n",
        "    self.conv2 = nn.Conv2d(bottleneck_channels,bottleneck_channels,kernel_size=3,stride=stride,padding=1)\n",
        "    self.bn2 =  nn.BatchNorm2d(bottleneck_channels)\n",
        "    self.act2 = nn.ReLU()\n",
        "\n",
        "    #3rd\n",
        "    self.conv3 = nn.Conv2d(bottleneck_channels,out_channels,kernel_size=1,stride=1)\n",
        "    self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "\n",
        "    if stride!=1 or in_channels!=out_channels:\n",
        "      self.shortcut = shortcut_projection(in_channels,out_channels,stride=stride)\n",
        "    else:\n",
        "      self.shortcut = nn.Identity()\n",
        "    self.act3 =  nn.ReLU()\n",
        "\n",
        "  def forward(self,x: torch.Tensor):\n",
        "    shortcut = self.shortcut(x)\n",
        "    x = self.act1(self.bn1(self.conv1(x)))\n",
        "    x = self.act2(self.bn2(self.conv2(x)))\n",
        "    x = self.bn3(self.conv3(x))\n",
        "    return  self.act3(x + shortcut)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GZpQ9Tg02cD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Resnet model"
      ],
      "metadata": {
        "id": "8MS0FBOvAtDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional,List\n",
        "#resnet is just stack of bottlenecks or residual  blocks\n",
        "class  ResnetBase(Module):\n",
        "  def __init__(self,n_blocks: List[int],n_channels: List[int],\n",
        "               bottlenecks:Optional[List[int]]=None,img_channels: int=3,first_kernel_size =  7):\n",
        "   super().__init__()\n",
        "   assert len(n_blocks)==len(n_channels)\n",
        "   assert bottlenecks is None or len(bottlenecks) == len(n_channels)\n",
        "\n",
        "   self.conv = nn.Conv2d(img_channels,n_channels[0],kernel_size=first_kernel_size,\n",
        "                         stride=2,padding=first_kernel_size//2)\n",
        "   self.bn = nn.BatchNorm2d(n_channels[0])\n",
        "\n",
        "   blocks = []\n",
        "   prev_channels = n_channels[0]\n",
        "\n",
        "   for i,channels in enumerate(n_channels):\n",
        "    stride = 2 if  len(blocks)==0  else 1\n",
        "    if  bottlenecks is  None:\n",
        "      blocks.append(ResidualBlock(prev_channels,channels,stride=stride))\n",
        "    else:\n",
        "      blocks.append(BottleneckResidualBlock(prev_channels,bottlenecks[i],channels,stride=stride))\n",
        "\n",
        "    prev_channels = channels\n",
        "\n",
        "    for _  in range(n_blocks[i]-1):\n",
        "      if bottlenecks  is  None:\n",
        "        blocks.append(ResidualBlock(channels,channels,stride=1))\n",
        "      else:\n",
        "        blocks.append(BottleneckResidualBlock(prev_channels,bottlenecks[i],channels,stride=1))\n",
        "   self.blocks = nn.Sequential(*blocks)\n",
        "\n",
        "  def forward(self,x:torch.Tensor):\n",
        "    x = self.bn(self.conv(x))\n",
        "    x = self.blocks(x)\n",
        "    x = x.view(x.shape[0], x.shape[1], -1)\n",
        "    return x.mean(dim=-1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1nTFBP0oACWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from labml import experiment\n",
        "from labml.configs import option\n",
        "from labml_nn.experiments.cifar10 import CIFAR10Configs"
      ],
      "metadata": {
        "id": "2vm07eY5R3kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Configs(CIFAR10Configs):\n",
        "  n_blocks: List[int]  = [3,3,3]\n",
        "  n_channels: List[int] =  [16,32,64]\n",
        "  bottlenecks:  Optional[List[int]] = None\n",
        "  first_kernel_size: int = 3\n"
      ],
      "metadata": {
        "id": "KYNCULgMRu9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@option(Configs.model)\n",
        "def  _resnet(c:Configs):\n",
        "  base = ResnetBase(c.n_blocks,c.n_channels,c.bottlenecks,img_channels=3,first_kernel_size=c.first_kernel_size)\n",
        "  classification =  nn.Linear(c.n_channels[-1],10)\n",
        "  model  = nn.Sequential(base,classification)\n",
        "  return  model.to(c.device)"
      ],
      "metadata": {
        "id": "chMpqalKSeW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  experiment.create(name='resnet',comment='cifar10')\n",
        "  conf =  Configs()\n",
        "  experiment.configs(conf,{\n",
        "      'bottlenecks':[8,16,16],\n",
        "      'n_blocks':[6,6,6],\n",
        "\n",
        "      'optimizer.optimizer':'Adam',\n",
        "      'optimizer.learning_rate':2.5e-4,\n",
        "\n",
        "      'epochs':500,\n",
        "      'train_batch_size':256,\n",
        "\n",
        "      'train_dataset':'cifar10_train_augmented',\n",
        "      'valid_dataset':'cifar10_valid_no_augment',\n",
        "  })\n",
        "  experiment.add_pytorch_models({'model': conf.model})\n",
        "  with experiment.start():\n",
        "    conf.run()\n",
        "if __name__ =='__main__':\n",
        "  main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dp_H-AffTlDZ",
        "outputId": "375ddef4-c880-419c-cb3d-f70d52e68ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style=\"overflow-x: scroll;\">\n",
              "Prepare model...\n",
              "  Prepare device.device...\n",
              "    Prepare device.device_info<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t46.92ms</span>\n",
              "  Prepare device.device<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t51.51ms</span>\n",
              "Prepare model<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t194.47ms</span>\n",
              "<strong><span style=\"color: #DDB62B\">No labml server url specified. Please start a labml server and specify the URL. Docs: https://github.com/labmlai/labml/tree/master/app</span></strong>\n",
              "\n",
              "<strong><span style=\"text-decoration: underline\">resnet</span></strong>: <span style=\"color: #208FFB\">744475124f5b11f0947f0242ac1c000c</span>\n",
              "\t<strong><span style=\"color: #DDB62B\">cifar10</span></strong>\n",
              "[clean]: <strong><span style=\"color: #DDB62B\">\"\"</span></strong>\n",
              "Initialize...\n",
              "  Prepare mode<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t3.77ms</span>\n",
              "Initialize<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t53.76ms</span>\n",
              "Prepare validator...\n",
              "  Prepare valid_loader...\n",
              "    Prepare valid_dataset<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t774.65ms</span>\n",
              "  Prepare valid_loader<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t847.96ms</span>\n",
              "Prepare validator<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t937.10ms</span>\n",
              "Prepare trainer...\n",
              "  Prepare train_loader...\n",
              "    Prepare train_dataset<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t1,032.10ms</span>\n",
              "  Prepare train_loader<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t1,102.73ms</span>\n",
              "Prepare trainer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t1,127.65ms</span>\n",
              "Prepare training_loop...\n",
              "  Prepare loop_count<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t27.19ms</span>\n",
              "Prepare training_loop<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t176.13ms</span>\n",
              "<strong><span style=\"color: #DDB62B\">       0:  </span></strong>Train:<span style=\"color: #C5C1B4\">  ...</span><span style=\"color: #208FFB\">  0ms  </span>  <span style=\"color: #208FFB\">0ms</span><span style=\"color: #D160C4\">  0:00m/  0:00m  </span>\n",
              "Prepare optimizer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t7.84ms</span>\n",
              "Prepare optimizer.optimizer...\n",
              "  Prepare optimizer.weight_decay_obj<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t2.26ms</span>\n",
              "Prepare optimizer.optimizer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t7.22ms</span>\n",
              "<strong><span style=\"color: #DDB62B\">  50,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  49,572ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,806ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 2.17649</span> accuracy.train: <span style=\"color: #C5C1B4\">0.183900</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.96039</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.177300</span>  <span style=\"color: #208FFB\">43,516ms</span><span style=\"color: #D160C4\">  0:00m/  6:01m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 100,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  44,501ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,363ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.82944</span> accuracy.train: <span style=\"color: #C5C1B4\">0.262000</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.85666</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.271800</span>  <span style=\"color: #208FFB\">45,719ms</span><span style=\"color: #D160C4\">  0:01m/  6:19m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 150,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  55,048ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,654ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.91460</span> accuracy.train: <span style=\"color: #C5C1B4\">0.296060</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.72552</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.304400</span>  <span style=\"color: #208FFB\">47,906ms</span><span style=\"color: #D160C4\">  0:02m/  6:36m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 200,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  50,140ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 5,052ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.77141</span> accuracy.train: <span style=\"color: #C5C1B4\">0.323200</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.70373</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.342600</span>  <span style=\"color: #208FFB\">50,098ms</span><span style=\"color: #D160C4\">  0:03m/  6:54m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 250,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  52,779ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 5,079ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.70268</span> accuracy.train: <span style=\"color: #C5C1B4\">0.352700</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.62511</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.370700</span>  <span style=\"color: #208FFB\">51,970ms</span><span style=\"color: #D160C4\">  0:04m/  7:08m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 300,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  49,898ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,685ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.72068</span> accuracy.train: <span style=\"color: #C5C1B4\">0.370740</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.59692</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.393000</span>  <span style=\"color: #208FFB\">54,001ms</span><span style=\"color: #D160C4\">  0:05m/  7:24m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 350,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  54,076ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,745ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.78457</span> accuracy.train: <span style=\"color: #C5C1B4\">0.388180</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.57725</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.412200</span>  <span style=\"color: #208FFB\">53,385ms</span><span style=\"color: #D160C4\">  0:05m/  7:18m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 400,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  50,460ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,419ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.68495</span> accuracy.train: <span style=\"color: #C5C1B4\">0.403540</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.55689</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.420100</span>  <span style=\"color: #208FFB\">52,915ms</span><span style=\"color: #D160C4\">  0:06m/  7:14m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 450,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  48,594ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,680ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.58614</span> accuracy.train: <span style=\"color: #C5C1B4\">0.420320</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.50249</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.433100</span>  <span style=\"color: #208FFB\">52,720ms</span><span style=\"color: #D160C4\">  0:07m/  7:11m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 500,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  52,685ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,682ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.54009</span> accuracy.train: <span style=\"color: #C5C1B4\">0.428820</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.48758</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.445700</span>  <span style=\"color: #208FFB\">52,693ms</span><span style=\"color: #D160C4\">  0:08m/  7:10m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 550,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  55,235ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,713ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.58899</span> accuracy.train: <span style=\"color: #C5C1B4\">0.437320</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.47602</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.452000</span>  <span style=\"color: #208FFB\">53,215ms</span><span style=\"color: #D160C4\">  0:09m/  7:13m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 600,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  49,329ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 5,102ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.54791</span> accuracy.train: <span style=\"color: #C5C1B4\">0.448600</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.45809</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.461600</span>  <span style=\"color: #208FFB\">53,132ms</span><span style=\"color: #D160C4\">  0:10m/  7:12m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 650,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  52,155ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,680ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.43834</span> accuracy.train: <span style=\"color: #C5C1B4\">0.459100</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.47227</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.465700</span>  <span style=\"color: #208FFB\">53,586ms</span><span style=\"color: #D160C4\">  0:11m/  7:15m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 700,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  52,961ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,799ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.61835</span> accuracy.train: <span style=\"color: #C5C1B4\">0.467620</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.42254</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.474100</span>  <span style=\"color: #208FFB\">53,627ms</span><span style=\"color: #D160C4\">  0:12m/  7:14m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 750,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  57,255ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,831ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.38529</span> accuracy.train: <span style=\"color: #C5C1B4\">0.471560</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.41064</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.487600</span>  <span style=\"color: #208FFB\">54,265ms</span><span style=\"color: #D160C4\">  0:13m/  7:19m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 800,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  53,203ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 5,044ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.32723</span> accuracy.train: <span style=\"color: #C5C1B4\">0.477160</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.42154</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.494800</span>  <span style=\"color: #208FFB\">54,028ms</span><span style=\"color: #D160C4\">  0:13m/  7:16m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 850,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  50,742ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,632ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.69846</span> accuracy.train: <span style=\"color: #C5C1B4\">0.481920</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.43506</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.495700</span>  <span style=\"color: #208FFB\">53,826ms</span><span style=\"color: #D160C4\">  0:14m/  7:13m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 900,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  49,077ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,854ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.65095</span> accuracy.train: <span style=\"color: #C5C1B4\">0.487820</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.39080</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.500100</span>  <span style=\"color: #208FFB\">53,874ms</span><span style=\"color: #D160C4\">  0:15m/  7:13m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 950,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  54,630ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,571ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.32031</span> accuracy.train: <span style=\"color: #C5C1B4\">0.498600</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.38358</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.504900</span>  <span style=\"color: #208FFB\">53,813ms</span><span style=\"color: #D160C4\">  0:16m/  7:11m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,000,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  50,246ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,896ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.32096</span> accuracy.train: <span style=\"color: #C5C1B4\">0.499880</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.39952</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.507700</span>  <span style=\"color: #208FFB\">53,554ms</span><span style=\"color: #D160C4\">  0:17m/  7:08m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,050,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  50,502ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,558ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.27730</span> accuracy.train: <span style=\"color: #C5C1B4\">0.511220</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.38149</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.511300</span>  <span style=\"color: #208FFB\">53,594ms</span><span style=\"color: #D160C4\">  0:18m/  7:08m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,100,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  49,497ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 5,019ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.26173</span> accuracy.train: <span style=\"color: #C5C1B4\">0.516600</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.34827</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.513500</span>  <span style=\"color: #208FFB\">53,700ms</span><span style=\"color: #D160C4\">  0:19m/  7:08m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,150,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  54,736ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,663ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.29441</span> accuracy.train: <span style=\"color: #C5C1B4\">0.520160</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.36172</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.519800</span>  <span style=\"color: #208FFB\">53,700ms</span><span style=\"color: #D160C4\">  0:20m/  7:07m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,200,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  62,133ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 5,039ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.30848</span> accuracy.train: <span style=\"color: #C5C1B4\">0.523920</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.31557</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.530400</span>  <span style=\"color: #208FFB\">55,074ms</span><span style=\"color: #D160C4\">  0:21m/  7:17m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,250,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  51,502ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 5,135ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.51006</span> accuracy.train: <span style=\"color: #C5C1B4\">0.527800</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.33439</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.528100</span>  <span style=\"color: #208FFB\">54,789ms</span><span style=\"color: #D160C4\">  0:22m/  7:14m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,300,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  49,942ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,586ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.08014</span> accuracy.train: <span style=\"color: #C5C1B4\">0.534460</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.30594</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.531100</span>  <span style=\"color: #208FFB\">53,628ms</span><span style=\"color: #D160C4\">  0:22m/  7:03m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,350,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  53,009ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,659ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.33575</span> accuracy.train: <span style=\"color: #C5C1B4\">0.539840</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.29765</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.541800</span>  <span style=\"color: #208FFB\">53,367ms</span><span style=\"color: #D160C4\">  0:23m/  7:00m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,400,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  51,249ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 5,156ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.31933</span> accuracy.train: <span style=\"color: #C5C1B4\">0.544600</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.27351</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.542200</span>  <span style=\"color: #208FFB\">53,192ms</span><span style=\"color: #D160C4\">  0:24m/  6:58m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,450,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  49,164ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,766ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.42917</span> accuracy.train: <span style=\"color: #C5C1B4\">0.548620</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.27580</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.550800</span>  <span style=\"color: #208FFB\">53,007ms</span><span style=\"color: #D160C4\">  0:25m/  6:56m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,500,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  49,323ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,547ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.27782</span> accuracy.train: <span style=\"color: #C5C1B4\">0.554620</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.25749</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.553800</span>  <span style=\"color: #208FFB\">52,958ms</span><span style=\"color: #D160C4\">  0:26m/  6:54m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,550,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  57,038ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,585ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.35876</span> accuracy.train: <span style=\"color: #C5C1B4\">0.556640</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.23958</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.556400</span>  <span style=\"color: #208FFB\">53,007ms</span><span style=\"color: #D160C4\">  0:27m/  6:54m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,600,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  50,086ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,748ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.34758</span> accuracy.train: <span style=\"color: #C5C1B4\">0.561460</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.22996</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.561900</span>  <span style=\"color: #208FFB\">52,871ms</span><span style=\"color: #D160C4\">  0:28m/  6:52m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,650,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  48,422ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,624ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.05147</span> accuracy.train: <span style=\"color: #C5C1B4\">0.564880</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.24235</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.566500</span>  <span style=\"color: #208FFB\">52,511ms</span><span style=\"color: #D160C4\">  0:29m/  6:48m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,700,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  54,159ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,691ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.30928</span> accuracy.train: <span style=\"color: #C5C1B4\">0.571880</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.22959</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.567900</span>  <span style=\"color: #208FFB\">53,032ms</span><span style=\"color: #D160C4\">  0:30m/  6:51m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,750,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  56,198ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,570ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.16750</span> accuracy.train: <span style=\"color: #C5C1B4\">0.573320</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.21107</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.573000</span>  <span style=\"color: #208FFB\">53,611ms</span><span style=\"color: #D160C4\">  0:30m/  6:55m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,800,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  54,826ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,527ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.18816</span> accuracy.train: <span style=\"color: #C5C1B4\">0.577060</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.21070</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.579200</span>  <span style=\"color: #208FFB\">54,764ms</span><span style=\"color: #D160C4\">  0:31m/  7:04m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,850,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  48,440ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,695ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.29844</span> accuracy.train: <span style=\"color: #C5C1B4\">0.579100</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.21349</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.579700</span>  <span style=\"color: #208FFB\">53,895ms</span><span style=\"color: #D160C4\">  0:32m/  6:56m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,900,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  49,102ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,536ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.39911</span> accuracy.train: <span style=\"color: #C5C1B4\">0.584020</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.19779</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.578400</span>  <span style=\"color: #208FFB\">53,594ms</span><span style=\"color: #D160C4\">  0:33m/  6:53m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">1,950,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  57,310ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,942ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.16243</span> accuracy.train: <span style=\"color: #C5C1B4\">0.588860</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.20550</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.584800</span>  <span style=\"color: #208FFB\">53,913ms</span><span style=\"color: #D160C4\">  0:34m/  6:54m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,000,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  36,069ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,635ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.21393</span> accuracy.train: <span style=\"color: #C5C1B4\">0.591160</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.20001</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.583300</span>  <span style=\"color: #208FFB\">50,731ms</span><span style=\"color: #D160C4\">  0:35m/  6:27m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,050,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  36,144ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,500ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.16100</span> accuracy.train: <span style=\"color: #C5C1B4\">0.594380</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.19727</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.587600</span>  <span style=\"color: #208FFB\">45,799ms</span><span style=\"color: #D160C4\">  0:35m/  5:45m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,100,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  37,743ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 4,215ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.31567</span> accuracy.train: <span style=\"color: #C5C1B4\">0.598100</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.17278</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.590600</span>  <span style=\"color: #208FFB\">43,233ms</span><span style=\"color: #D160C4\">  0:36m/  5:23m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,150,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  41,881ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,281ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.01319</span> accuracy.train: <span style=\"color: #C5C1B4\">0.606640</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.18888</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.596900</span>  <span style=\"color: #208FFB\">41,620ms</span><span style=\"color: #D160C4\">  0:37m/  5:09m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,200,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  42,441ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,931ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.22877</span> accuracy.train: <span style=\"color: #C5C1B4\">0.606820</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.15495</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.597700</span>  <span style=\"color: #208FFB\">41,007ms</span><span style=\"color: #D160C4\">  0:37m/  5:03m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,250,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  36,596ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,684ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 0.98470</span> accuracy.train: <span style=\"color: #C5C1B4\">0.608560</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.14543</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.600700</span>  <span style=\"color: #208FFB\">41,093ms</span><span style=\"color: #D160C4\">  0:38m/  5:03m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,300,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  35,815ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,578ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 0.94295</span> accuracy.train: <span style=\"color: #C5C1B4\">0.611640</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.15691</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.604400</span>  <span style=\"color: #208FFB\">40,227ms</span><span style=\"color: #D160C4\">  0:39m/  4:55m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,350,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  36,616ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,911ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.12684</span> accuracy.train: <span style=\"color: #C5C1B4\">0.615140</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.13033</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.611800</span>  <span style=\"color: #208FFB\">39,736ms</span><span style=\"color: #D160C4\">  0:39m/  4:51m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,400,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  41,191ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,851ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.17846</span> accuracy.train: <span style=\"color: #C5C1B4\">0.620460</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.12971</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.611100</span>  <span style=\"color: #208FFB\">39,639ms</span><span style=\"color: #D160C4\">  0:40m/  4:49m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,450,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  41,221ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,738ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.00850</span> accuracy.train: <span style=\"color: #C5C1B4\">0.618500</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.14557</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.610800</span>  <span style=\"color: #208FFB\">39,368ms</span><span style=\"color: #D160C4\">  0:41m/  4:46m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,500,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  36,150ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,751ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.09096</span> accuracy.train: <span style=\"color: #C5C1B4\">0.623860</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.11672</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.611400</span>  <span style=\"color: #208FFB\">39,176ms</span><span style=\"color: #D160C4\">  0:41m/  4:44m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,550,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  37,042ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,322ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.07877</span> accuracy.train: <span style=\"color: #C5C1B4\">0.632960</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.08738</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.606100</span>  <span style=\"color: #208FFB\">39,019ms</span><span style=\"color: #D160C4\">  0:42m/  4:42m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,600,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  35,957ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,516ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 0.92905</span> accuracy.train: <span style=\"color: #C5C1B4\">0.632780</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.08876</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.623600</span>  <span style=\"color: #208FFB\">38,818ms</span><span style=\"color: #D160C4\">  0:43m/  4:40m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,650,000:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">  35,837ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 3,408ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.14871</span> accuracy.train: <span style=\"color: #C5C1B4\">0.632840</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.08181</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.620200</span>  <span style=\"color: #208FFB\">38,668ms</span><span style=\"color: #D160C4\">  0:43m/  4:38m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">2,695,056:  </span></strong>Train:<span style=\"color: #C5C1B4\">  89%</span><span style=\"color: #208FFB\">  34,507ms  </span>Valid:<span style=\"color: #C5C1B4\">  90%</span><span style=\"color: #208FFB\"> 3,068ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 0.95669</span> accuracy.train: <span style=\"color: #C5C1B4\">0.636630</span> loss.valid: <span style=\"color: #C5C1B4\"> 1.07613</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.626194</span>  <span style=\"color: #208FFB\">38,668ms</span><span style=\"color: #D160C4\">  0:44m/  4:37m  </span></pre>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L3clgvNbYeB7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}